## Q5

A. `k=5` and `k=7` performed best in the first part of Q4 of A2. For the second part, model 2 would be
best to use because we're talking about medical results. For a screening test, we are ok with false
positives but want to minimize false negatives. This is because false positives can get filtered out
by future tests, but false negatives would immediately exit the pipeline and may not find out about their
true condition until the disease has progressed significantly.

B. In Q5 of A2, the QDA with a flat prior performs the best. A likely reason for this is that QDA uses
quadratic decision boundaries, and we note that QDA with estimated priors also performed reasonably well. Another
possible reason is that we assume features are multivariate normal conditioned on the classes.

C. Naive Bayes may perform poorly because we assume independence between the features, which may be incorrect.

D. QDA performs better than LDA. This may be the case because the underlying ground truth is quadratic rather
than linear in nature.

E. Using a flat prior performs better than estimating it from the data. We see this for both QDA and LDA. This
may be the case because the flat prior we chose is more representative of the underlying ground truth than
what the model is able to estimate based on the data.

F. The class that is easiest to classify is most likely `B`, as it stands out compared to the other classes
in the feature plots. This is most evident when they are plotted as normal distributions, but also visible
in the scatter plot matrix.
