## Q6

A. There are 72 observations and 5147 predictors (the last column is the correct class).

B. No, as the there is no inflection point. We would expect the results to start deteriorating.

C. Yes, as we see an inflection point for the log lambdas.

D. KNN seems to do worse as k increases, although k=7 seems slightly better
than both k=5 and k = 9. The difference between KNN and the penalized methods
is that KNN looks for proximity in a very high dimensional space (which may be
high enough to make the distances very large/not meaningful in this case), whereas
the lasso and ridge models are better able to learn weights by penalizing 
incorrect predictions.

E. Both ridge models had not only the highest accuracy, but also the lowest
standard deviation on that accuracy, making either of them the best choice
of the models we constructed.

F. Based on my table, choosing the random forest makes the most sense as it has
the lowest RMSE. Intuitively, it also is not unreasonable (though maybe a bit
surprising) that there is no strong predictive power in the dataset (ie. the 
metrics we have in the dataset are largely context-sensitive from one university to
the next).

G. The best tuning parameters are alpha = 0.1 and alpha = 0.2 respectively. This
is very close to ridge, because ridge uses an alpha of 0 while lasso uses an
alpha of 1.

H. After trying both, the scaled approach was marginally better when considering
interactions as well, but worse otherwise. If our model was accurate at estimating
the underlying ground truth, scaling should either have no effect or a positive
effect on our predictive power, so this suggests that KNN is not the correct 
model for this data.

I. The best KNN model was the vanilla KNN. One possible explanation for this is
that it is slightly more general, and thus not overfitting the data.

J. This dataset is from 1995. The out of state tuition for the University of Illinois at Urbana-Champaign at that time was 7560.
